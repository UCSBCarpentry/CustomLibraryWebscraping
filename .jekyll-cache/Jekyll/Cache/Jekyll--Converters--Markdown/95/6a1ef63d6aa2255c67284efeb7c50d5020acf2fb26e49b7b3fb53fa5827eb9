I"Ê'<h1 id="using-the-scraper-chrome-extension">Using the Scraper Chrome extension</h1>

<p>Now we are finally ready to do some web scraping. For this lesson, we will be using two UCSB department webpages: East Asian Languages and Cultural Studies and Jewish Studies. We are interested in scrapping contact information from faculty within these departments with the help of Xpath and Scraper. To do so, we will use the Scraper extension in the Chrome browser (refer to the <a href="FIXME">Setup</a> section for help installing these tools).
First, let‚Äôs focus our attention on the East Asian Languages and Cultural Studies webpage <a href="https://www.eastasian.ucsb.edu/people/faculty/">https://www.eastasian.ucsb.edu/people/faculty/</a>. We are interested in downloading the list of faculty names and their email addresses.
&lt;Image 1 East asian website&gt;</p>

<h2 id="scrape-similar">Scrape similar</h2>
<p>With the extension installed, we can select the first row in the faculty list, do a right-click and choose ‚ÄúScrape similar‚Äù from the contextual menu.</p>

<p>&lt;Image 2 East asian website/scrape&gt;</p>

<p>You can select the picture as well. Make sure you do not right-click on a hyperlinked text. 
Alternatively, the ‚ÄúScrape similar‚Äù option can also be accessed from the Scraper extension icon:</p>

<p>&lt;Image 3 Scraper web browser&gt;</p>

<p>Either operation will bring up the Scraper window:</p>

<p>&lt;Image 4 Scraper Asian studies with blue and red rectangles&gt;</p>

<p>We can notice that Scraper has generated XPath queries that correspond to the data we had selected upon calling it. The Selector (highlighted in blue in the above screenshot) has been set to //tr[td] which selects all the rows of the table, delimiting the data we want to extract.
In fact, we can try out that query using the technique that we learned in the previous section by typing the following in the browser console:</p>

<div class="callout highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Tip: Use the following shortcuts to Open Console: Panel Mac (Command+Option+J) Windows/Linux (Control+Shift+J). 
Remember: ```&lt;tr&gt;``` defines a row in a table and ```&lt;td&gt;``` defines a cell is a table
``` $x("//tr[td]")```
</code></pre></div></div>

<p>The query will return something like:</p>
<div class="output highlighter-rouge"><div class="highlight"><pre class="highlight"><code>output &lt;- (48)
</code></pre></div></div>

<p>Which we can explore in the console and check for highlights to make sure this is the right data.</p>

<p>Could you guess why we got 48 as a result?</p>

<p>There are 24 rows with faculty profiles, but in between them we had tr box shadows, if we unselect ‚ÄúExclude empty results‚Äù which is set by default, we will get empty rows in our output. So it is wise to keep this option always selected.</p>

<p>Scraper also recognized that there were four columns in that table, and has accordingly created four such columns (highlighted in red in the screenshot), each with its own XPath selector, <code class="highlighter-rouge">*[1]</code>, <code class="highlighter-rouge">*[2]</code>, <code class="highlighter-rouge">*[3]</code> and <code class="highlighter-rouge">*[4]</code>.</p>

<p>To understand what this means, we have to remember that XPath queries are relative to the current context node. The context node has been set by the Selector query above, so those queries are relative to the array of tr elements that have been selected.
We can replicate their effect by trying out the following expression in the console:</p>
<div class="source highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$x("//tr[td]/*[4]")
</code></pre></div></div>

<p>This should select only the first column of the table. The same goes for the second column.
But in this case, we don‚Äôt need to fiddle with the XPath queries too much, as Scraper was able to deduce them for us, and we can use the export functions to either create a Google Spreadsheet with the results, or copy them into the clipboard in Tab Separated Values (TSV) format for pasting into a text document or a spreadsheet.
There is a bit of data cleaning we might want to do prior to that, though. 
The first column is empty because we have selected the photo and scraper recognizes that as an element, however, images are not included in the scrapping process, so we can remove it using the red (-) icon and click on scrape to see the change. Let‚Äôs do the same thing with column three because we are not interested in their positions or specialties now.
We also want to rename the other columns remaining accordingly, so let‚Äôs change them to Faculty_name and Contact_info.</p>

<h2 id="custom-xpath-queries">Custom XPath queries</h2>
<p>Sometimes, however, we do have to do a bit of work to get Scraper to select the data elements that we are interested in.
Note that we still have other info such as office location and times along with emails. So what if we want to get a column only with emails instead? We should add a new column and rename it as Email and use Xpath to help us to refine that. To add another column in Scraper, use the little green ‚Äú+‚Äù icon in the columns list. 
Let‚Äôs inspect the link to identify it on the developer‚Äôs console the exact path for the email addresses. Select the email &gt; right-click (make sure to not click in the email) &gt; Inspect. Then, hover the mouse over the email &gt; right-click &gt; copy &gt; copy Xpath. Note that there will be an option to copy the Full path but you do not need that as we have already scrapped from a portion of the website.
Tip: You can copy the path to a notepad, it will help you to compare with scrap and understand better where the element you are interested in is located. 
You should have the path bellow or something slightly different if you have selected other faculty email as the tr [row number] will represent the data you have selected:</p>

<p>&lt;code //*[@id=‚Äùsite-main‚Äù]/div/div/div[2]/div/table/tbody/tr[1]/td[4]/a &gt;</p>

<p>&lt;Challenge:&gt;</p>

<p>Which path would you have to provide to Scraper to get the emails in one column?</p>

<p>Answer:
You should get a column with emails with the following path expression after hitting scrape
./td[4]/a</p>

<p>&lt;output?&gt;
Note that Scraper gave you a starting path based on what you have scraped //tr[td], so you have only to add the continuation of it. In order to tell Scraper extension we are only interested in the emails, we will have to indicate the data that is in the fourth column and add the specific path to the email address. Don‚Äôt forget the dot (.) in the beginning of the Xpath expression. As we have learned in the previous lesson that is how you tell the path is in the current context node.</p>

<p>You can remove the contact row now and copy the output to the clipboard. 
Alternatively, you can export the output to Google Docs. Following the steps below:</p>

<p>&lt;header HOW TO DIVIDE THE DIFFERENT EXAMPLES - SECTION? &gt;</p>

<p>Now let‚Äôs turn to the Jewish Studies faculty webpage &lt;link (https://www.jewishstudies.ucsb.edu/people) &gt; for practicing XPath queries a little bit more. Note that differently from the profiles in the previous webpage, here the information is not displayed in well-defined rows. So, when we scrape the web page data, we should get one row per faculty with one string of data.</p>

<p>&lt;Image 5 Jewish Studies website&gt;
&lt;Image 6 Scraper Jewish studies&gt;</p>

<p>If we want to have this data in a more reusable format, we will have to create columns indicating the exact path we want to scrape the data from, considering that these paths will be a continuation of the one highlighted in the image above.</p>

<p>For this particular case, we want to have four columns: 1) Name, 2) Email, 3) Position, and 4) Office Location. Using the function to inspect where the element is located on the webpage, identify the correct paths, and scrape the information we need.</p>

<p>For the first column ‚ÄúName‚Äù we will have to inspect where the name is located to get the right path to it. Select one of the Faculty names &gt; right-click &gt; inspect. It will prompt the developer window as indicated below:</p>

<p>&lt;Image 7 Jewish Studies with developer window&gt;</p>

<p>Look for the name element by navigating the div carrot, right-click, then choose Copy Xpath.</p>

<p>You should get this path:</p>

<p>&lt;code //*[@id=‚Äùblock-system-main‚Äù]/div/div/div/div/section[1]/div/div/div/div/div[1]/div[1]/span &gt;</p>

<p>Note that you only have to specify in the expression things that are not included in the original XPath automatically created by Scaper. Compare the two and see how we can express the path to Scraper.</p>

<p>&lt;challenge Question:  In this case, either of the following paths would work. Do you know why?: &gt;</p>

<p>&lt;code
./div[1]/span
./div/span
code&gt;</p>

<p>Alternatively, you can also get it right if you use:</p>

<p>&lt;code
./div/span/a 
./div[1]/span/a</p>
<blockquote>

</blockquote>

<p>&lt; solution Answer: 
In the first case telling that the element in the first node of that particular div is consistent throughout other names on the website. Omitting it won‚Äôt change the outcome, as you are describing that you are interested in the content of that div child node. 
If you provide the path with the extra /a you are telling Scraper to get the information that is in another child node, which happens to also include the faculty name, linking to a bio webpage. Again, including [1] or not does not change the outcome. &gt;
&lt;Image 8 Jewish Studies Scraper with 4 paths leading to the same result&gt;</p>

<p>&lt;challenge Exercise: &gt;</p>

<p>Now that you have learned how to get the right path to create columns for names, follow the same steps to get the three other columns Emails, Position, and Office Location.</p>

<p>After completing all steps you should have the following output:</p>

<p>&lt;Image  9Jewish Studies Scraper with final exercise completed&gt;</p>

<p>&lt;Solution:
./div[4]/div[1]/div/a (Email)
./div[2]/div[2]/div/d (Position)
./div[4]/div[3]/div/d (Office)&gt;</p>

:ET